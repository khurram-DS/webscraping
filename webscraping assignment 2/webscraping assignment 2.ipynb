{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in\n",
    "         “Bangalore” location. You have to scrape the job-title, job-location, company_name,\n",
    "          experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException ,ElementNotInteractableException,InvalidElementStateException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome(r\"C:\\Users\\khurr\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.naukri.com/data-analyst-jobs-in-bangalore?k=data%20analyst&l=bangalore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling empty list to store the different data\n",
    "job_titles=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting Job title \n",
    "title_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for j in title_tags[:10]:\n",
    "    job_titles.append(j.text)\n",
    "#extracting location \n",
    "location_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for j in location_tags[:10]:\n",
    "    job_location.append(j.text)\n",
    "#extracting company name\n",
    "company_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for j in company_tags[:10]:\n",
    "    company_name.append(j.text)\n",
    "#extracting Experience required data\n",
    "experience_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "for j in experience_tags[:10]:\n",
    "    experience_required.append(j.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job titles ----->>> ['NiFi Data Analyst', 'Senior Analyst-Data Science', 'Associate - Data Analyst ( Revenue Planning and Management)', 'Data Research Analyst', 'Business Data Analyst', 'Data Analyst Analyzing', 'Market Research Data Analyst', 'Data Analyst', 'Data Analyst ( SAS / R /Python ) openings', 'Data Analyst ( SAS / R /Python ) openings']\n",
      "\n",
      "Job_location ----->>> ['Bengaluru', 'Bengaluru', 'Bengaluru', 'Delhi NCR, Bengaluru', 'Bengaluru / Bangalore', 'Bengaluru', 'Bengaluru', 'Pune, Mumbai, Bengaluru', 'Chennai, Pune, Delhi NCR, Mumbai, Other International Location, Bengaluru, Hyderabad, Kolkata, onsite', 'Chennai, Pune, Delhi NCR, Mumbai, Other International Location, Bengaluru, Hyderabad, Kolkata, onsite']\n",
      "\n",
      "company_name ----->>> ['Capgemini Technology Services India Limited', 'Accenture Solutions Pvt Ltd', 'Myntra Designs Pvt. Ltd.', 'Headhunters Point', 'ASM Enterprise Solutions Private Limited', 'Cistup Indian Institute of Science', 'Robas Research', 'TresVista Financial', 'ACHYUTAS SOFT PRIVATE LIMITED', 'ACHYUTAS SOFT PRIVATE LIMITED']\n",
      "\n",
      "experience_required ----->>> ['4-6 Yrs', '5-8 Yrs', '2-4 Yrs', '1-6 Yrs', '5-8 Yrs', '2-5 Yrs', '2-5 Yrs', '0-1 Yrs', '0-5 Yrs', '5-10 Yrs']\n"
     ]
    }
   ],
   "source": [
    "# All extracted data\n",
    "print('Job titles ----->>>',job_titles)\n",
    "print()\n",
    "print('Job_location ----->>>',job_location)\n",
    "print()\n",
    "print('company_name ----->>>',company_name)\n",
    "print()\n",
    "print('experience_required ----->>>',experience_required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "# as I extracted all the data\n",
    "# Before saving the data into a data frame length check the lenth all the data must be of equal lenghts before saving the data.\n",
    "print(len(job_titles),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets save the extracted data\n",
    "import pandas as pd\n",
    "Data_analyst=pd.DataFrame({})\n",
    "Data_analyst['job_titles']=job_titles\n",
    "Data_analyst['job_location']=job_location\n",
    "Data_analyst['company_name']=company_name\n",
    "Data_analyst['experience_required']=experience_required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we got the data lets extract the data in csv file\n",
    "Data_analyst.to_csv('Data_analyst_jobs_naukri.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_titles</th>\n",
       "      <th>job_location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NiFi Data Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Capgemini Technology Services India Limited</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Analyst-Data Science</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Accenture Solutions Pvt Ltd</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Associate - Data Analyst ( Revenue Planning an...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Research Analyst</td>\n",
       "      <td>Delhi NCR, Bengaluru</td>\n",
       "      <td>Headhunters Point</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>ASM Enterprise Solutions Private Limited</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst Analyzing</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Cistup Indian Institute of Science</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Market Research Data Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Robas Research</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Pune, Mumbai, Bengaluru</td>\n",
       "      <td>TresVista Financial</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst ( SAS / R /Python ) openings</td>\n",
       "      <td>Chennai, Pune, Delhi NCR, Mumbai, Other Intern...</td>\n",
       "      <td>ACHYUTAS SOFT PRIVATE LIMITED</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst ( SAS / R /Python ) openings</td>\n",
       "      <td>Chennai, Pune, Delhi NCR, Mumbai, Other Intern...</td>\n",
       "      <td>ACHYUTAS SOFT PRIVATE LIMITED</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          job_titles  \\\n",
       "0                                  NiFi Data Analyst   \n",
       "1                        Senior Analyst-Data Science   \n",
       "2  Associate - Data Analyst ( Revenue Planning an...   \n",
       "3                              Data Research Analyst   \n",
       "4                              Business Data Analyst   \n",
       "5                             Data Analyst Analyzing   \n",
       "6                       Market Research Data Analyst   \n",
       "7                                       Data Analyst   \n",
       "8          Data Analyst ( SAS / R /Python ) openings   \n",
       "9          Data Analyst ( SAS / R /Python ) openings   \n",
       "\n",
       "                                        job_location  \\\n",
       "0                                          Bengaluru   \n",
       "1                                          Bengaluru   \n",
       "2                                          Bengaluru   \n",
       "3                               Delhi NCR, Bengaluru   \n",
       "4                              Bengaluru / Bangalore   \n",
       "5                                          Bengaluru   \n",
       "6                                          Bengaluru   \n",
       "7                            Pune, Mumbai, Bengaluru   \n",
       "8  Chennai, Pune, Delhi NCR, Mumbai, Other Intern...   \n",
       "9  Chennai, Pune, Delhi NCR, Mumbai, Other Intern...   \n",
       "\n",
       "                                  company_name experience_required  \n",
       "0  Capgemini Technology Services India Limited             4-6 Yrs  \n",
       "1                  Accenture Solutions Pvt Ltd             5-8 Yrs  \n",
       "2                     Myntra Designs Pvt. Ltd.             2-4 Yrs  \n",
       "3                            Headhunters Point             1-6 Yrs  \n",
       "4     ASM Enterprise Solutions Private Limited             5-8 Yrs  \n",
       "5           Cistup Indian Institute of Science             2-5 Yrs  \n",
       "6                               Robas Research             2-5 Yrs  \n",
       "7                          TresVista Financial             0-1 Yrs  \n",
       "8                ACHYUTAS SOFT PRIVATE LIMITED             0-5 Yrs  \n",
       "9                ACHYUTAS SOFT PRIVATE LIMITED            5-10 Yrs  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#My extracted data\n",
    "Data_analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in\n",
    "“Bangalore” location. You have to scrape the job-title, job-location,\n",
    "company_name, full job-description. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome(r\"C:\\Users\\khurr\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.naukri.com/data-scientist-jobs-in-bangalore?k=data%20scientist&l=bangalore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling empty list to store the different data\n",
    "job_titles=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "job_description=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting Job title \n",
    "title_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for j in title_tags[:10]:\n",
    "    job_titles.append(j.text)\n",
    "#extracting location \n",
    "location_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for j in location_tags[:10]:\n",
    "    job_location.append(j.text)\n",
    "#extracting company name\n",
    "company_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for j in company_tags[:10]:\n",
    "    company_name.append(j.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting each job link\n",
    "Job_link=[]\n",
    "url_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for j in url_tags[:10]:\n",
    "    Job_link.append(j.get_attribute('href'))\n",
    "#Making for loop for extracting average ratings of every phone\n",
    "for j in Job_link:\n",
    "    driver.get(j)\n",
    "    try:\n",
    "        job_description.append((driver.find_element_by_xpath(\"//section[@class='job-desc']\")).text)\n",
    "    except NoSuchElementException:\n",
    "        job_description.append(\"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "# as I extracted all the data\n",
    "# Before saving the data into a data frame length check the lenth all the data must be of equal lenghts before saving the data.\n",
    "print(len(job_titles),len(job_location),len(company_name),len(job_description),len(Job_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets save the extracted data\n",
    "import pandas as pd\n",
    "Data_scientist=pd.DataFrame({})\n",
    "Data_scientist['job_titles']=job_titles\n",
    "Data_scientist['job_location']=job_location\n",
    "Data_scientist['company_name']=company_name\n",
    "Data_scientist['Job_link']=Job_link\n",
    "Data_scientist['job_description']=job_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_scientist['job_description']=Data_scientist['job_description'].str.replace('\\n',' - ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_titles</th>\n",
       "      <th>job_location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>Job_link</th>\n",
       "      <th>job_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist/Data Analyst-immediate</td>\n",
       "      <td>Chennai, Pune, Bengaluru, Hyderabad</td>\n",
       "      <td>CAIA-Center For Artificial Intelligence &amp; Adva...</td>\n",
       "      <td>https://www.naukri.com/job-listings-data-scien...</td>\n",
       "      <td>Job description - Dear Candidate -  - Schedule...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HCL hiring Data scientist with exp in machine ...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>HCL Technologies Limited</td>\n",
       "      <td>https://www.naukri.com/job-listings-hcl-hiring...</td>\n",
       "      <td>Job description - Dear Candidate, -  - Greetin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Machine Learning</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>AugmatrixGo</td>\n",
       "      <td>https://www.naukri.com/job-listings-data-scien...</td>\n",
       "      <td>Job description - Roles and Responsibilities -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Machine Learning</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>BLUE YONDER INDIA PRIVATE LIMITED</td>\n",
       "      <td>https://www.naukri.com/job-listings-data-scien...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - Machine Learning</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>BLUE YONDER INDIA PRIVATE LIMITED</td>\n",
       "      <td>https://www.naukri.com/job-listings-data-scien...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist -Machine Learning</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>BLUE YONDER INDIA PRIVATE LIMITED</td>\n",
       "      <td>https://www.naukri.com/job-listings-data-scien...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Software Developer - Data Scientist / NLP / Ma...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Cunesoft India Private Limited</td>\n",
       "      <td>https://www.naukri.com/job-listings-software-d...</td>\n",
       "      <td>Job description - Roles and Responsibilities -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Machine Learning - Remote Wor...</td>\n",
       "      <td>Delhi NCR, Bengaluru, Anywhere in India</td>\n",
       "      <td>Doji Ltd</td>\n",
       "      <td>https://www.naukri.com/job-listings-data-scien...</td>\n",
       "      <td>Job description - Please note that this role w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>https://www.naukri.com/job-listings-data-scien...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist (Healthcare/Pharma Domain prefe...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>https://www.naukri.com/job-listings-data-scien...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          job_titles  \\\n",
       "0              Data Scientist/Data Analyst-immediate   \n",
       "1  HCL hiring Data scientist with exp in machine ...   \n",
       "2                  Data Scientist - Machine Learning   \n",
       "3                  Data Scientist - Machine Learning   \n",
       "4                  Data Scientist - Machine Learning   \n",
       "5                   Data Scientist -Machine Learning   \n",
       "6  Software Developer - Data Scientist / NLP / Ma...   \n",
       "7  Data Scientist - Machine Learning - Remote Wor...   \n",
       "8                                     Data Scientist   \n",
       "9  Data Scientist (Healthcare/Pharma Domain prefe...   \n",
       "\n",
       "                              job_location  \\\n",
       "0      Chennai, Pune, Bengaluru, Hyderabad   \n",
       "1                                Bengaluru   \n",
       "2                                Bengaluru   \n",
       "3                                Bengaluru   \n",
       "4                                Bengaluru   \n",
       "5                                Bengaluru   \n",
       "6                    Bengaluru / Bangalore   \n",
       "7  Delhi NCR, Bengaluru, Anywhere in India   \n",
       "8                                Bengaluru   \n",
       "9                                Bengaluru   \n",
       "\n",
       "                                        company_name  \\\n",
       "0  CAIA-Center For Artificial Intelligence & Adva...   \n",
       "1                           HCL Technologies Limited   \n",
       "2                                        AugmatrixGo   \n",
       "3                  BLUE YONDER INDIA PRIVATE LIMITED   \n",
       "4                  BLUE YONDER INDIA PRIVATE LIMITED   \n",
       "5                  BLUE YONDER INDIA PRIVATE LIMITED   \n",
       "6                     Cunesoft India Private Limited   \n",
       "7                                           Doji Ltd   \n",
       "8                      GENPACT India Private Limited   \n",
       "9                      GENPACT India Private Limited   \n",
       "\n",
       "                                            Job_link  \\\n",
       "0  https://www.naukri.com/job-listings-data-scien...   \n",
       "1  https://www.naukri.com/job-listings-hcl-hiring...   \n",
       "2  https://www.naukri.com/job-listings-data-scien...   \n",
       "3  https://www.naukri.com/job-listings-data-scien...   \n",
       "4  https://www.naukri.com/job-listings-data-scien...   \n",
       "5  https://www.naukri.com/job-listings-data-scien...   \n",
       "6  https://www.naukri.com/job-listings-software-d...   \n",
       "7  https://www.naukri.com/job-listings-data-scien...   \n",
       "8  https://www.naukri.com/job-listings-data-scien...   \n",
       "9  https://www.naukri.com/job-listings-data-scien...   \n",
       "\n",
       "                                     job_description  \n",
       "0  Job description - Dear Candidate -  - Schedule...  \n",
       "1  Job description - Dear Candidate, -  - Greetin...  \n",
       "2  Job description - Roles and Responsibilities -...  \n",
       "3                                                 NA  \n",
       "4                                                 NA  \n",
       "5                                                 NA  \n",
       "6  Job description - Roles and Responsibilities -...  \n",
       "7  Job description - Please note that this role w...  \n",
       "8                                                 NA  \n",
       "9                                                 NA  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets check the data\n",
    "Data_scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_titles</th>\n",
       "      <th>job_location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>Job_link</th>\n",
       "      <th>job_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist/Data Analyst-immediate</td>\n",
       "      <td>Chennai, Pune, Bengaluru, Hyderabad</td>\n",
       "      <td>CAIA-Center For Artificial Intelligence &amp; Advanced Analytics</td>\n",
       "      <td>https://www.naukri.com/job-listings-data-scientist-data-analyst-immediate-caia-center-for-artificial-intelligence-advanced-analytics-chennai-pune-bengaluru-bangalore-hyderabad-secunderabad-0-to-3-years-210920000599?src=jobsearchDesk&amp;sid=16117536189885305&amp;xp=1&amp;px=1</td>\n",
       "      <td>Job description - Dear Candidate -  - Schedule a Telephonic Interview ( Please call for confirmation) : Mon- Sat from 11:00am to 5:00pm -  - OR Walk-In to the Corporate office between Monday to Friday from 11:00am to 5:00pm - Contact person : -  - Manigandan -+91 7299917200 - Shantha +91 9790993237 -  -  - Systech Solutions - Temple Steps - Tower 3, 6th Floor - 184-187 Anna Salai - Saidapet, Chennai 600015 - India (Near Little Mount Metro Station) - Roles and Responsibilities -  - Greetings from CAIA ! - A great opportunity to enter the world of future technologies - Data Science, Analytics, AI, Data Visualization - Applications invited from all Freshers and experienced candidates aspiring to make a career in Artificial Intelligence and Advanced Analytics and Data Science. - In case you are trying to shift your career to Analytics and/or AI domain please do connect with us to know more. - What is needed from you? - - An Educational background in any one of the following- BE/B.Tech, ME/M Tech, MSc, BSc/MSc Maths and Statistics, B Com, BCA, BSc CS, BSC IT, MSC IT, MCA - - Skills relating to Mathematics/Statistics. - - Natural passion towards numbers, business, coding, Analytics and Artificial Intelligence, Machine Learning, visualization - - Good verbal and written communication skills - - Ability to understand domains in businesses across various sectors - - Freshers who wish to start their career in Analytics and AI and professionals who wish to up skill or change their domain to analytics and emerging technologies are free to apply. - Selection procedure includes - - Online Aptitude Test - - Logical Ability Test / Written Test - On being shortlisted, you will be have to undergo a one-one discussion with our counsellor for further evaluation and processing of your Resume. - What you can expect from us? - You will get trained on the following modules for a period of 12-14 weeks: - -SQL &amp; PLSQL - -Data Wrangling using Python - -Statistics for Machine Learning, - -Artificial Intelligence, Data Interpretation - -Supervised &amp; Unsupervised Learning, - -NLP &amp; Deep Learning - -Cloud Data Lake - -Business intelligence &amp; Data Visualization - -Simulation Projects - What is the expected Outcome? - At the end of the Training you are expected to be well versed with the following: - - Analysis of large and complex data sets from multiple sources - - Development and evaluation of data analytics models, algorithms and solutions - - Understanding/implementation of ML algorithms, performance tuning and reporting - - Implementation of algorithms to mine targeted data and the ability to convert data into a business story - - Translation of business requirements into technical requirements; Data extraction, preparation and transformation - - Identification, development and implementation of statistical techniques and algorithms that address business challenges and adds value to the organisation - - Requirement Analysis and communication of findings in the form of a meaningful story with the stakeholders - Center for Artificial Intelligence &amp; Advanced Analytics (CAIA) focuses on the following: - 1. Global Research on emerging trends, technologies and applications in AI and Advanced Analytics - 2. Advanced Training programs for readying the future ready workforce - 3. Solutions to herald the futuristic lifestyle and workspaces in the field of AI and Data Science. - http://www.centerforaia.com/ - Center for Artificial Intelligence and Advanced Analytics (Center for AIA) is the brainchild of experienced and visionary alumni of IIT Madras and Bombay. Digital leaders 5F World and Systech Solutions have joined hands to create a venture for architecting the future of society, workforce, governments and businesses. 5F World specializes in designing solutions around digital platforms and Systech Solutions has an expertise in architecting Artificial Intelligence and Advanced Analytics solutions for Fortune 500 companies through specialized programmed. - 5F World - 5F World is a leader in digital transformational journeys and has brought together the best minds in industry, academia and technology domains to develop a unique framework to transform stakeholder journeys through innovation and digitalization of businesses and education institutions. - Systech Solutions - Systech Solutions is a leading organisation in Data Strategy, Management &amp; Analytics services provider with deep technology expertise and over 20 years of industry experience. Systech Solutions helps empower clients with innovative, data-driven solutions to reimagine their enterprise and has forged partnerships with industry-leading technology providers to develop a full spectrum of data services. -  - Website - http://www.centerforaia.com/ -  - https://inflexion-analytix-private-limited.business.site/?m=true -  -  -  - Contact Person - Shantha/Manigandan - Phone Number - 9790993237 / 7299917200 - Email - manigandan@centerforaia.com -  - Desired Candidate Profile -  - Perks and Benefits -  - RoleBusiness Analyst - Industry TypeBPO, Call Centre, ITeS - Functional AreaIT Software - DBA, Datawarehousing - Employment TypeFull Time, Permanent - Role CategorySystem Design/Implementation/ERP/CRM - Education - UG :B.Tech/B.E. in Any Specialization, Any Graduate in Any Specialization, Diploma in Any Specialization, Other Graduate, B.Com in Any Specialization, B.Sc in Any Specialization - PG :MBA/PGDM in Any Specialization, Other, Post Graduation Not Required, MS/M.Sc(Science) in Any Specialization, M.Tech in Any Specialization, MCA in Any Specialization, PG Diploma in Any Specialization, M.Com in Any Specialization - Key Skills - Business IntelligenceArtificial IntelligenceNatural Language ProcessingNeural NetworksData MiningMachine LearningDeep LearningSQLData ScienceRNLPCloud ComputingData AnalysisPLSQLData WarehousingETLPredictive AnalyticsPython</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HCL hiring Data scientist with exp in machine learning &amp;SQL-Bangalore!</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>HCL Technologies Limited</td>\n",
       "      <td>https://www.naukri.com/job-listings-hcl-hiring-data-scientist-with-exp-in-machine-learning-sql-bangalore-hcl-technologies-limited-bengaluru-bangalore-5-to-10-years-190121001223?src=jobsearchDesk&amp;sid=16117536189885305&amp;xp=2&amp;px=1</td>\n",
       "      <td>Job description - Dear Candidate, -  - Greetings from HCL!!! - We are looking for Data scientists with experience in machine learning algorithms and strong SQL experience. - If you are Keen with Below Skill Set. Please do send the Updated CV with details such as current ctc, expected ctc and notice period to m_divvya@hcl.com / 8754448290.We are looking only for immediate joiners. Candidates with more than 30 days notice please don't apply. -  -  - Technical Skills: - Overall 5+ years of experience in advanced analytics and leading/mentoring team members - Proficient in Python &amp; SQL with minimum 2-3 years of hands on experience - Solid fundamentals, knowledge of supervised, unsupervised, reinforcement learning machine learning and deep learning algorithms, such as classifiers, cluster analysis, dimension reduction, regression, CNN, RNN, DQN, temporal difference methods, sequence modeling, probability theory, algorithm design and theory of computation, information retrieval - Ability to work and execute projects on both structured and unstructured data in a big data environment • Strong at preparing data for analysis using SQL and experience working with the industry leading BI tools like Tableau, visualizing the data and executing to specifications - Experience of end to end implementation of predictive analytics projects for at least 1-3 years • Exposure to text analytics, web scraping, big data technologies and graph databases would be desirable • Exposure to visualization tools • Experience of intent to learn software domain related to VMware products and the way virtualization software/hardware -  - Preferred Skills: - Good understanding of API connections and data pipelining • Knowledge with Natural Language Processing (e.g. word2vec, doc2vec, attention, LDA) • Understanding of different model performance metrics and hyperparameter optimization • Business Acumen, ability to translate business needs into a set of workable, specific requirements • Well versed with MS PowerPoint/Visio - Ability to understand business requirements, KPIs and convert into analytical hypothesis in a structured and logical manner along with solution identification • Ability to handle multiple projects at a time in terms of multitasking, prioritization, allocation and team management • Ability to coordinate and work within multiple business units from project management perspective • Ability to work across geographies and interact with global stakeholders • Prior experience working in Agile methodologies/JIRA would be a plus - What we are looking for: - BS/BE in Computer Sciences, Math, Statistics or related field. Masters preferred. - Proficient in SQL and experience with efficient processing of large data sets. Ability to write sophisticated and optimized queries against large databases • Proficient in data visualization tools such as Mode Analytics or Tableau • Proficient in Excel • Experience in statistical computing with Python/R • Ability to handle several concurrent activities with strong organizational skills and attention to detail We're team players. You'll do well if you're one too - RoleIT/Technical Content Developer - Industry TypeIT-Software, Software Services - Functional AreaIT Software - Application Programming, Maintenance - Employment TypeFull Time, Permanent - Role CategoryOther - Education - UG :B.Tech/B.E. in Any Specialization - Key Skills - Machine LearningSQL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Machine Learning</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>AugmatrixGo</td>\n",
       "      <td>https://www.naukri.com/job-listings-data-scientist-machine-learning-augmatrixgo-bengaluru-bangalore-2-to-5-years-140121905423?src=jobsearchDesk&amp;sid=16117536189885305&amp;xp=3&amp;px=1</td>\n",
       "      <td>Job description - Roles and Responsibilities -  -  - - Selecting features, building and optimizing classifiers using machine learning techniques -  - - Data mining using state-of-the-art methods -  - - Enhancing data collection procedures to include information that is relevant for building analytic systems -  - - Processing, cleansing, and verifying the integrity of data used for analysis -  - - Doing ad-hoc analysis and presenting results in a clear manner -  - - Creating automated anomaly detection systems and constant tracking of its performance -  - Skills Required : -  - - Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc. -  - - Experiences with one or more of the following is highly desirable: HPC/Parallelization, operationalizing ML models; cloud computing (e.g. Google Cloud, AWS, etc.); familiarity with ML frameworks such as Tensorflow, Theano, MXNet, etc -  - - Good experience in a few of the following areas: deep neural networks, reinforcement learning, Markov Random Fields, Bayesian networks, semi-supervised learning, computer vision, image processing, signal processing, distributed computing, and/or numerical optimization -  - - 2+ years of experience with computer vision and deep learning solutions, including image classification, object detection, segmentation, and equivalent computer vision-based vision tasks -  - - Experience with common data science toolkits, such as R, Weka, NumPy, etc . Excellence in at least one of these is highly desirable -  - - Proficiency in using query languages such as SQL, Hive, Pig -  - - Good applied statistics skills, such as distributions, statistical testing, regression, etc. -  - - Good scripting and programming skills -  - - Data-oriented personality -  - - B.Tech/M.Tech degree in from reputed institutes like IIT / NIT / BITS - RoleData Analyst - Industry TypeIT-Software, Software Services - Functional AreaAnalytics &amp; Business Intelligence - Employment TypeFull Time, Permanent - Role CategoryAnalytics &amp; BI - Education - UG :B.Tech/B.E. in Any Specialization - PG :M.Tech in Any Specialization - Doctorate :Doctorate Not Required - Key Skills - HiveRCloud ComputingData ScientistComputer VisionMachine LearningDeep LearningSQLPig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Machine Learning</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>BLUE YONDER INDIA PRIVATE LIMITED</td>\n",
       "      <td>https://www.naukri.com/job-listings-data-scientist-machine-learning-blue-yonder-india-private-limited-bengaluru-bangalore-5-to-8-years-130121902169?src=jobsearchDesk&amp;sid=16117536189885305&amp;xp=4&amp;px=1</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - Machine Learning</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>BLUE YONDER INDIA PRIVATE LIMITED</td>\n",
       "      <td>https://www.naukri.com/job-listings-data-scientist-machine-learning-blue-yonder-india-private-limited-bengaluru-bangalore-3-to-5-years-130121902167?src=jobsearchDesk&amp;sid=16117536189885305&amp;xp=5&amp;px=1</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist -Machine Learning</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>BLUE YONDER INDIA PRIVATE LIMITED</td>\n",
       "      <td>https://www.naukri.com/job-listings-data-scientist-machine-learning-blue-yonder-india-private-limited-bengaluru-bangalore-4-to-8-years-270121903312?src=jobsearchDesk&amp;sid=16117536189885305&amp;xp=6&amp;px=1</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Software Developer - Data Scientist / NLP / Machine Learning</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Cunesoft India Private Limited</td>\n",
       "      <td>https://www.naukri.com/job-listings-software-developer-data-scientist-nlp-machine-learning-cunesoft-india-private-limited-bengaluru-bangalore-3-to-6-years-190121001281?src=jobsearchDesk&amp;sid=16117536189885305&amp;xp=7&amp;px=1</td>\n",
       "      <td>Job description - Roles and Responsibilities - We are looking for a competent and enthusiastic candidate with the below requirement. This vital role ensures Cunesoft India Pvt Ltd (a Phlexglobal Company) Bangalore can provide a high-quality end product to internal and external users. This position requires strong technical and communication skills as well as both independent and team working, including working closely with all other areas of the software delivery team and the rest of the Technology department. -  - Roles and Responsibilities -  - Key Activities - Develop and improve the existing data mining and NLP related processes within our Regulatory Data Management platform - Develop new ways of improving and transforming the regulatory processes of Phlexglobal customers. - Interact with product management, project management and development teams to develop additional modules and functions within the Phlexglobal Cloud Platform - Design and create solutions for pre specified modules and functions - Use existing tools and techniques to develop and test new and existing work - Define, create and execute automated test cases, i.e. unit tests - Participate in troubleshooting and triaging of issues with different teams to drive towards root cause identification and resolution - Support production deployment of applications and perform validation testing during the off-hours maintenance windows - Support and fix existing and new identified issues by either customers or internal test teams. -  -  - Desired Candidate Profile -  - Required Skills &amp; Experience - Minimum 3+ years working experience in NLP, Artificial Intelligence, Machine Learning, Text Mining, Neural Networks - Strong programming skills using PYTHON - In depth experience with OpenNLP, Stanford NLP or related NLP / data mining technologies - In depth experience with Python and data libraries such as scikit learn, pandas, numpy, etc. - Selecting features, building and optimizing classifiers using machine learning techniques - Excellent understanding of Machine Learning Techniques and Algorithms. - Must have Data mining / Natural Language Processing experience - Must have very good understanding ofGIT - Processing, Cleansing, and verifying the integrity of data - Develop custom data models and algorithms to apply to data sets. - Defining validation strategies - Defining the preprocessing or feature engineering to be done on a given dataset - Defining data augmentation pipelines - Training models and tuning their hyperparameters - Analyzing the errors of the model and designing strategies to overcome them - Deploying models to production -  - Added advantages - 3+ years experience using Microsoft .NET / C# - Exposure to ML.Net, AutoML, NimbusML, etc - Good knowledge of Microsoft Visual Studio is preferred - Good to have Microsoft SQL Server, preferably Microsoft SQL Azure - Previous experience in the Life sciences area - Other requirements - Excellent verbal and written communication skills - Must be flexible, independent and self motivated - Punctual, Regular and consistent attendance -  - Education: - BS degree in Information Systems, Computer Science, Web Systems, Electrical Engineering, Mathematics or domain related working experience - As part of the Interview process, could you please complete the Titanic project and share the predication results on Kaggle.com to move forward with interview. -  - https://www.kaggle.com/c/titanic -  - Candidates with relevant experience kindly contact me. -  - We are looking for a candidate who can join us immediately or in less than 15-20 days -  - Srini - +91 9731007277 - sarumugam@phlexglobal.com -  -  -  - RoleSoftware Developer - Industry TypePharma, Biotech, Clinical Research - Functional AreaIT Software - Application Programming, Maintenance - Employment TypeFull Time, Permanent - Role CategoryProgramming &amp; Design - Education - UG :Any Graduate in Any Specialization - PG :Other - Doctorate :Other Doctorate - Key Skills - pandaspythonnlpscikitlearndataminingneuralnetworkdeeplearningmachinelearningdatasciencenumpynaturallanguageprocessingartificialintelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Machine Learning - Remote Working</td>\n",
       "      <td>Delhi NCR, Bengaluru, Anywhere in India</td>\n",
       "      <td>Doji Ltd</td>\n",
       "      <td>https://www.naukri.com/job-listings-data-scientist-machine-learning-remote-working-doji-ltd-delhi-ncr-bengaluru-bangalore-anywhere-in-india-2-to-5-years-171220006270?src=jobsearchDesk&amp;sid=16117536189885305&amp;xp=8&amp;px=1</td>\n",
       "      <td>Job description - Please note that this role will be Remote / Home-based for next 6 to 12 months. -  - In DOJI, we are building a next generation marketplace and setting new standards for e-commerce buyers and sellers worldwide. We are a UK based tech start-up, founded by three passionate entrepreneurs with a track record of building and exiting successful ventures. - We're excited to build this world-class team that is going to reshape the way people buy and sell consumer goods. -  - Roles and Responsibilities -  - Perform exploratory and statistical analyses to understand and predict our customer behaviours, identify bottlenecks, and answer critical business questions. - Build and deploy scalable machine learning models and oversee their performance against KPIs. - Forecast our users conversion, engagement, and churn with rigorous statistical models - Build overall data capability of our organisation by performing complex data processing, building data pipelines and developing data products which can be directly used by our business users such as marketing and product teams -  - Requirements -  - Following are the mandatory skills &amp; experience requirements for this role: - Been a data scientist for 2+ years in a commercial set-up - Direct experience in performing statistical analyses or building a variety of machine learning models from complex, specialised or large data pools. - Passion for understanding user behaviour and building solutions to optimise customer experience and growth. - Demonstrated competency with unsupervised machine learning algorithms (k-means clustering, isolation forests etc.) and / or supervised algorithms (logistic regression, SVM, Random Forests, GBM etc.) - Direct experience using programming languages such as Python or R for statistical and/or numeric computing - Undergraduate degree in a quantitative discipline (maths, statistics, econometrics etc.) or computer science -  - Although the following requirements are not mandatory, however we would strongly prefer candidates with this skill and experience. - We would prefer someone who also has experience in: data engineering, building data pipelines and cloud (AWS, Azure or GCP). - Experience with additional programming languages used for data processing such as SQL, Hive, PySpark, Scala etc. - Experience with consumer retail or e-commerce data - Postgraduate degree in a quantitative discipline or computer science -  - Perks and Benefits -  - A very competitive package of 15 to 20 Lacs - Be part of a start-up with an entrepreneurial mindset that thinks big, with a long-term vision. - Be the owner of your own development in an environment that is full of opportunities, learning, growth, expansion and challenging projects. - Share and learn with the team, amongst great professionals and experts. - An excellent work environment, with everything that you need to enjoy a great experience -  - Since this role will be 'Remote' (e.g. home office) during the initial stages, you will be responsible to ensure proper working conditions (computer and related equipment, reliable internet connection, etc) and availability during normal business working hours. As per business needs, you could be asked to work from an office based office location in the future. - In Doji, we work hard to promote a culture of inclusiveness and diversity that seeks equality and values from different perspectives. We believe in building trust and fairness amongst people and making a positive impact on the environment. - Should you require reasonable adjustments throughout the hiring process, please don't hesitate to get in touch with us. - RoleData Analyst - Industry TypeInternet, Ecommerce - Functional AreaAnalytics &amp; Business Intelligence - Employment TypeFull Time, Permanent - Role CategoryAnalytics &amp; BI - Education - UG :Any Graduate in Any Specialization - Key Skills - Data ScienceMachine LearningPython - PysparkRHiveLogistic RegressionData Engineeringdata scientistSVMStatisticsSQL - Skills highlighted with ‘‘ are preferred keyskills</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>https://www.naukri.com/job-listings-data-scientist-genpact-india-private-limited-bengaluru-bangalore-5-to-10-years-120121008663?src=jobsearchDesk&amp;sid=16117536189885305&amp;xp=9&amp;px=1</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist (Healthcare/Pharma Domain preferred)</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>https://www.naukri.com/job-listings-data-scientist-healthcare-pharma-domain-preferred-genpact-india-private-limited-bengaluru-bangalore-6-to-10-years-070121010487?src=jobsearchDesk&amp;sid=16117536189885305&amp;xp=10&amp;px=1</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "display(HTML(Data_scientist.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage:\n",
    "    You have to use the location and salary filter.\n",
    "    You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "    You have to scrape the job-title, job-location, company_name,\n",
    "    experience_required.\n",
    "    The location filter to be used is “Delhi/NCR”\n",
    "    The salary filter to be used is “3-6” lakhs\n",
    "Note- All of the above steps have to be done in code. No step is to be done\n",
    "manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome(r\"C:\\Users\\khurr\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.naukri.com/data-scientist-jobs?k=data%20scientist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspecting location\n",
    "location=driver.find_element_by_xpath(\"//div[2][@class='mt-8 chckBoxCont']\")\n",
    "try:\n",
    "    location.click()\n",
    "except ElementNotInteractableException:\n",
    "    location.get(location.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspecting salary\n",
    "salary=driver.find_element_by_xpath(\"//div[@data-filter-id='salaryRange']/div[2]\")\n",
    "try:\n",
    "    salary.click()\n",
    "except ElementNotInteractableException:\n",
    "    salary.get(salary.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling empty list to store the different data\n",
    "job_titles=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting Job title \n",
    "title_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for j in title_tags[:10]:\n",
    "    job_titles.append(j.text)\n",
    "#extracting location \n",
    "location_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for j in location_tags[:10]:\n",
    "    job_location.append(j.text)\n",
    "#extracting company name\n",
    "company_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for j in company_tags[:10]:\n",
    "    company_name.append(j.text)\n",
    "#extracting Experience required data\n",
    "experience_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "for j in experience_tags[:10]:\n",
    "    experience_required.append(j.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job titles ----->>> ['Data Scientist - Python/Machine Learning', 'Tech Mahindra hiring For Data Scientist- Noida', 'Data Scientist - Commercial Planning and Analysis', 'Data Scientist - Machine Learning/ Artificial Intelligence - IT', 'GCP Skilled Analytics Resources (Data engineer / Data scientists)', 'Data Scientist', 'Data Scientist Machine Learning', 'Data Scientist', 'Business Analyst - Data Scientist', 'Analyst - Data Scientist']\n",
      "\n",
      "Job_location ----->>> ['Noida', 'Noida', 'Delhi NCR, Gurgaon', 'Delhi/NCR Delhi NCR, Noida', 'Pune, Bengaluru, Gurgaon', 'Gurgaon Gurugram', 'Gurgaon', 'Delhi NCR', 'Gurgaon', 'Gurgaon']\n",
      "\n",
      "company_name ----->>> ['Jubna', 'tech mahindra ltd', 'Air Asia India Limited', 'Talent Acceleration Corridor', 'Aerial Telecom Solutions Pvt. Ltd.', 'IBM India Pvt. Limited', 'Delhivery', 'Eighteen Pixels India Private Limited', 'HyreFox Consultants Pvt Ltd', 'HyreFox Consultants Pvt Ltd']\n",
      "\n",
      "experience_required ----->>> ['5-8 Yrs', '5-10 Yrs', '1-6 Yrs', '6-11 Yrs', '3-8 Yrs', '3-5 Yrs', '1-3 Yrs', '2-6 Yrs', '3-5 Yrs', '1-3 Yrs']\n"
     ]
    }
   ],
   "source": [
    "# All extracted data\n",
    "print('Job titles ----->>>',job_titles)\n",
    "print()\n",
    "print('Job_location ----->>>',job_location)\n",
    "print()\n",
    "print('company_name ----->>>',company_name)\n",
    "print()\n",
    "print('experience_required ----->>>',experience_required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "# as I extracted all the data\n",
    "# Before saving the data into a data frame length check the lenth all the data must be of equal lenghts before saving the data.\n",
    "print(len(job_titles),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets save the extracted data\n",
    "import pandas as pd\n",
    "Data_scientist=pd.DataFrame({})\n",
    "Data_scientist['job_titles']=job_titles\n",
    "Data_scientist['job_location']=job_location\n",
    "Data_scientist['company_name']=company_name\n",
    "Data_scientist['experience_required']=experience_required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we got the data lets extract the data in csv file\n",
    "Data_scientist.to_csv('Data_scientist_jobs_naukri.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_titles</th>\n",
       "      <th>job_location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist - Python/Machine Learning</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Jubna</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tech Mahindra hiring For Data Scientist- Noida</td>\n",
       "      <td>Noida</td>\n",
       "      <td>tech mahindra ltd</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Commercial Planning and Analysis</td>\n",
       "      <td>Delhi NCR, Gurgaon</td>\n",
       "      <td>Air Asia India Limited</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Machine Learning/ Artificial ...</td>\n",
       "      <td>Delhi/NCR Delhi NCR, Noida</td>\n",
       "      <td>Talent Acceleration Corridor</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GCP Skilled Analytics Resources (Data engineer...</td>\n",
       "      <td>Pune, Bengaluru, Gurgaon</td>\n",
       "      <td>Aerial Telecom Solutions Pvt. Ltd.</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon Gurugram</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist Machine Learning</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Delhivery</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi NCR</td>\n",
       "      <td>Eighteen Pixels India Private Limited</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Business Analyst - Data Scientist</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>HyreFox Consultants Pvt Ltd</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Analyst - Data Scientist</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>HyreFox Consultants Pvt Ltd</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          job_titles  \\\n",
       "0           Data Scientist - Python/Machine Learning   \n",
       "1     Tech Mahindra hiring For Data Scientist- Noida   \n",
       "2  Data Scientist - Commercial Planning and Analysis   \n",
       "3  Data Scientist - Machine Learning/ Artificial ...   \n",
       "4  GCP Skilled Analytics Resources (Data engineer...   \n",
       "5                                     Data Scientist   \n",
       "6                    Data Scientist Machine Learning   \n",
       "7                                     Data Scientist   \n",
       "8                  Business Analyst - Data Scientist   \n",
       "9                           Analyst - Data Scientist   \n",
       "\n",
       "                 job_location                           company_name  \\\n",
       "0                       Noida                                  Jubna   \n",
       "1                       Noida                      tech mahindra ltd   \n",
       "2          Delhi NCR, Gurgaon                 Air Asia India Limited   \n",
       "3  Delhi/NCR Delhi NCR, Noida           Talent Acceleration Corridor   \n",
       "4    Pune, Bengaluru, Gurgaon     Aerial Telecom Solutions Pvt. Ltd.   \n",
       "5            Gurgaon Gurugram                 IBM India Pvt. Limited   \n",
       "6                     Gurgaon                              Delhivery   \n",
       "7                   Delhi NCR  Eighteen Pixels India Private Limited   \n",
       "8                     Gurgaon            HyreFox Consultants Pvt Ltd   \n",
       "9                     Gurgaon            HyreFox Consultants Pvt Ltd   \n",
       "\n",
       "  experience_required  \n",
       "0             5-8 Yrs  \n",
       "1            5-10 Yrs  \n",
       "2             1-6 Yrs  \n",
       "3            6-11 Yrs  \n",
       "4             3-8 Yrs  \n",
       "5             3-5 Yrs  \n",
       "6             1-3 Yrs  \n",
       "7             2-6 Yrs  \n",
       "8             3-5 Yrs  \n",
       "9             1-3 Yrs  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#My extracted data\n",
    "Data_scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4: Write a python program to scrape data for first 10 job results for Data scientist\n",
    "Designation in Noida location. You have to scrape company_name, No. of days\n",
    "ago when job was posted, Rating of the company.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       company_name days_posted ratings\n",
      "0                         HDFC Bank          2d     3.7\n",
      "1      Salasar New Age Technologies        30d+     3.7\n",
      "2                    Biz2Credit Inc        30d+     3.3\n",
      "3  Simpplr Software India Pvt. Ltd.         24h       5\n",
      "4                         QuantumIT         15d     3.7\n",
      "5                    WSD Consultant        30d+     3.9\n",
      "6                          Techlive        30d+     3.7\n",
      "7                   Dürr Somac GmbH        30d+     3.8\n",
      "8      Salasar New Age Technologies        30d+     3.8\n",
      "9                     Angel & Genie         20d       3\n"
     ]
    }
   ],
   "source": [
    "# Function Definition\n",
    "def glassdoor(url):\n",
    "    driver=webdriver.Chrome(r\"C:\\Users\\khurr\\Downloads\\chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "    #fetching company name\n",
    "    company_name=[]\n",
    "    tags=driver.find_elements_by_xpath(\"//a[@class=' css-10l5u4p e1n63ojh0 jobLink']\")\n",
    "    for j in tags[:10]:\n",
    "        company_name.append(j.text)\n",
    "    #fetching days posted\n",
    "    days_posted=[]\n",
    "    tags=driver.find_elements_by_xpath(\"//div[@class='d-flex align-items-end pl-std css-mi55ob']\")\n",
    "    for j in tags[:10]:\n",
    "        days_posted.append(j.text)\n",
    "    #fetching ratings\n",
    "    ratings=[]\n",
    "    tags=driver.find_elements_by_xpath(\"//span[@class='compactStars ']\")\n",
    "    for j in tags[:10]:\n",
    "        ratings.append(j.text)\n",
    "    #making the data frame to store the data\n",
    "    job_df=pd.DataFrame({'company_name':company_name,\n",
    "                         'days_posted':days_posted,\n",
    "                         'ratings':ratings,})\n",
    "    #saving the dataframe to csv\n",
    "    job_df.to_csv('Data_Scientist_Glassdors.csv')\n",
    "    print(job_df)\n",
    "# Calling Function\n",
    "glassdoor('https://www.glassdoor.co.in/Job/noida-data-scientist-jobs-SRCH_IL.0,5_IC4477468_KO6,20.htm?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5:Write a python program to scrape the salary data for Data Scientist designation\n",
    "in Noida location.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Min\n",
    "salary, Max Salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         company_name num_salaries Average_salary  \\\n",
      "0                      Data Scientist  13 salaries    ₹ 12,81,419   \n",
      "1  See 14 salaries from all locations  11 salaries     ₹ 7,52,052   \n",
      "2                      Data Scientist  10 salaries     ₹ 9,98,925   \n",
      "3  See 22 salaries from all locations   9 salaries     ₹ 6,02,000   \n",
      "4                      Data Scientist   9 salaries     ₹ 7,71,657   \n",
      "5  See 37 salaries from all locations   8 salaries    ₹ 12,22,902   \n",
      "6                      Data Scientist   8 salaries     ₹ 7,91,015   \n",
      "7  See 83 salaries from all locations   7 salaries    ₹ 12,15,138   \n",
      "8                      Data Scientist   6 salaries    ₹ 10,21,889   \n",
      "9  See 73 salaries from all locations   5 salaries    ₹ 10,00,000   \n",
      "\n",
      "  minimum_salary max_salary  \n",
      "0          ₹456K   ₹11,789K  \n",
      "1          ₹420K    ₹1,636K  \n",
      "2          ₹585K    ₹2,200K  \n",
      "3          ₹336K    ₹1,024K  \n",
      "4          ₹595K    ₹2,769K  \n",
      "5          ₹727K    ₹1,597K  \n",
      "6          ₹509K    ₹1,168K  \n",
      "7          ₹629K    ₹1,719K  \n",
      "8          ₹804K    ₹1,281K  \n",
      "9          ₹205K    ₹1,835K  \n"
     ]
    }
   ],
   "source": [
    "# Function Definition\n",
    "def glassdoor(url):\n",
    "    driver=webdriver.Chrome(r\"C:\\Users\\khurr\\Downloads\\chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "    # fetching the company name\n",
    "    company_name=[]\n",
    "    tags=driver.find_elements_by_xpath(\"//p[@class='m-0']\")\n",
    "    for j in tags[:10]:\n",
    "        company_name.append(j.text)\n",
    "    #fetchinng the number of salary data\n",
    "    num_salaries=[]\n",
    "    tags=driver.find_elements_by_xpath(\"//p[@class='css-1uyte9r css-1kuy7z7 m-0 ']\")\n",
    "    for j in tags[:10]:\n",
    "        num_salaries.append(j.text)\n",
    "    #fetching average slary data\n",
    "    Average_salary=[]\n",
    "    tags=driver.find_elements_by_xpath(\"//div[@class='col-2 d-none d-md-flex flex-row justify-content-end']/strong\")\n",
    "    for j in tags[:10]:\n",
    "        Average_salary.append(j.text)\n",
    "    #fetching minimum salary data\n",
    "    minimum_salary=[]\n",
    "    tags=driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values common__flex__justifySpaceBetween common__flex__container ']/span[1]\")\n",
    "    for j in tags[:10]:\n",
    "        minimum_salary.append(j.text)\n",
    "    #fetching maximum salary data\n",
    "    max_salary=[]\n",
    "    tags=driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values common__flex__justifySpaceBetween common__flex__container ']/span[2]\")\n",
    "    for j in tags[:10]:\n",
    "        max_salary.append(j.text)\n",
    "    # saving the data in the data frame\n",
    "    salary_df=pd.DataFrame({'company_name':company_name,\n",
    "                         'num_salaries':num_salaries,\n",
    "                         'Average_salary':Average_salary,\n",
    "                          'minimum_salary':minimum_salary,\n",
    "                          'max_salary':max_salary })\n",
    "    # saving the data to csv file                     \n",
    "    salary_df.to_csv('Data_Scientist_Glassdors_salary.csv')\n",
    "    print(salary_df)\n",
    "# Calling Function\n",
    "\n",
    "glassdoor('https://www.glassdoor.co.in/Salaries/new-delhi-data-scientist-salary-SRCH_IL.0,9_IM1083_KO10,24.htm?clickSource=searchBtn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to\n",
    "scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Brand                                Product_description  \\\n",
      "0     FDA COLLECTION   Gradient, Mirrored, UV Protection Round, Round...   \n",
      "1   shah collections   UV Protection, Polarized, Mirrored Rectangular...   \n",
      "2           Fastrack   Gradient, UV Protection Wayfarer Sunglasses (F...   \n",
      "3         Phenomenal   UV Protection, Mirrored Retro Square Sunglasse...   \n",
      "4        like future   Mirrored Aviator Sunglasses (Free Size)  (Silv...   \n",
      "..                ...                                                ...   \n",
      "95    Rozzetta Craft   UV Protection, Gradient Rectangular Sunglasses...   \n",
      "96           Dannilo   Mirrored Wayfarer Sunglasses (Free Size)  (Blu...   \n",
      "97      Singco India   Mirrored, Riding Glasses, Others Sports Sungla...   \n",
      "98         ROYAL SON   UV Protection Retro Square Sunglasses (88)  (B...   \n",
      "99         Royal Son          Polarized Aviator Sunglasses (58)  (Black)   \n",
      "\n",
      "   price discount_percentage  \\\n",
      "0   ₹199             84% off   \n",
      "1   ₹219             78% off   \n",
      "2   ₹699             12% off   \n",
      "3   ₹399             80% off   \n",
      "4   ₹181             83% off   \n",
      "..   ...                 ...   \n",
      "95  ₹474             78% off   \n",
      "96  ₹236             76% off   \n",
      "97  ₹228             84% off   \n",
      "98  ₹569             71% off   \n",
      "99  ₹711             64% off   \n",
      "\n",
      "                                                 Link  \n",
      "0   https://www.flipkart.com/fda-collection-round-...  \n",
      "1   https://www.flipkart.com/shah-collections-rect...  \n",
      "2   https://www.flipkart.com/fastrack-wayfarer-sun...  \n",
      "3   https://www.flipkart.com/phenomenal-retro-squa...  \n",
      "4   https://www.flipkart.com/like-future-aviator-s...  \n",
      "..                                                ...  \n",
      "95  https://www.flipkart.com/rozzetta-craft-rectan...  \n",
      "96  https://www.flipkart.com/dannilo-wayfarer-sung...  \n",
      "97  https://www.flipkart.com/singco-india-sports-s...  \n",
      "98  https://www.flipkart.com/royal-son-retro-squar...  \n",
      "99  https://www.flipkart.com/royal-son-aviator-sun...  \n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Function Definition\n",
    "def flipkart_glasses(url):\n",
    "    driver=webdriver.Chrome(r\"C:\\Users\\khurr\\Downloads\\chromedriver.exe\")\n",
    "    urls = []\n",
    "    brand=[]\n",
    "    product_desc=[]\n",
    "    price=[]\n",
    "    discount_per=[]\n",
    "    #looping to fetch urls of each sunglasses till page 5\n",
    "    driver.get(url)\n",
    "    page=[]\n",
    "    url=driver.find_elements_by_xpath(\"//nav[@class='yFHi8N']/a\")\n",
    "    for i in url[0:5]:\n",
    "        page.append(i.get_attribute('href'))\n",
    "    for i in page:\n",
    "        driver.get(i)\n",
    "        soup= BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        prod_urls = soup.find_all('a', attrs ={'class':'IRpwTa'})\n",
    "        for prod in prod_urls:\n",
    "            urls.append('https://www.flipkart.com'+prod.get('href'))\n",
    "            \n",
    "    #loop to scrap required details from each sunglasses page\n",
    "    for url in urls:\n",
    "        driver.get(url)\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        n = soup.find('span',attrs={'class':'G6XhRU'})\n",
    "        if n is not None:\n",
    "            brand.append(n.text.replace('\\n',''))\n",
    "        else:\n",
    "            brand.append('-')\n",
    "        desc = soup.find('span', attrs = {'class':'B_NuCI'})\n",
    "        if desc is not None:\n",
    "            product_desc.append(desc.text)\n",
    "        else:\n",
    "            product_desc.append('-')\n",
    "        prc = soup.find('div', attrs = {'class':'_30jeq3 _16Jk6d'})\n",
    "        if prc is not None:\n",
    "            price.append(prc.text.replace('\\n',''))\n",
    "        else:\n",
    "            price.append('-')\n",
    "        disc = soup.find('div', attrs = {'class':'_3Ay6Sb _31Dcoz pZkvcx'})\n",
    "        if disc is not None:\n",
    "            discount_per.append(disc.find('span').text.replace('\\n',''))\n",
    "        else:\n",
    "            discount_per.append('-')\n",
    "           \n",
    "        \n",
    "    glass_df=pd.DataFrame({'Brand':brand[:100],\n",
    "                           'Product_description':product_desc[:100],\n",
    "                            'price':price[:100],\n",
    "                            'discount_percentage':discount_per[:100],\n",
    "                            'Link':urls[:100]})\n",
    "    print(glass_df)\n",
    "    glass_df.to_csv('Flipkart_glass.csv', index = False)\n",
    "    \n",
    "    \n",
    "# Calling Function\n",
    "flipkart_glasses('https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to\n",
    "go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includesearpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace\n",
    "\n",
    "These are\n",
    "1. Rating\n",
    "2. Review_summary\n",
    "3. Full review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rating      Review_summary  \\\n",
      "0       5    Perfect product!   \n",
      "1       5       Great product   \n",
      "2       5    Perfect product!   \n",
      "3       5  Highly recommended   \n",
      "4       5    Perfect product!   \n",
      "..    ...                 ...   \n",
      "94      5        Does the job   \n",
      "95      3            Terrific   \n",
      "96      5                Nice   \n",
      "97      5              Super!   \n",
      "98      4   Worth every penny   \n",
      "\n",
      "                                          Full_review  \n",
      "0   Amazing phone with great cameras and better ba...  \n",
      "1   Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
      "2   It’s a must buy who is looking for an upgrade ...  \n",
      "3   iphone 11 is a very good phone to buy only if ...  \n",
      "4   Value for money❤️❤️\\nIts awesome mobile phone ...  \n",
      "..                                                ...  \n",
      "94  The phone is awesome undoubtedly and worth the...  \n",
      "95  Switched from Android to Iphone. great experie...  \n",
      "96  Iphone 11 black 64gb is really a cool phone\\n\\...  \n",
      "97  Amazing performance... Very happy with purchas...  \n",
      "98  Kudos to flipkart, delivered well in time. Pho...  \n",
      "\n",
      "[99 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Function Definition\n",
    "def iphone11(url):\n",
    "    driver=webdriver.Chrome(r\"C:\\Users\\khurr\\Downloads\\chromedriver.exe\")\n",
    "    urls = []\n",
    "    Rating=[]\n",
    "    Review_summary=[]\n",
    "    Full_review=[]\n",
    "    \n",
    "    #looping to fetch urls of each sunglasses till page 10\n",
    "    driver.get(url)\n",
    "    urls=[]\n",
    "    url=driver.find_elements_by_xpath(\"//nav[@class='yFHi8N']/a\")\n",
    "    for i in url[0:10]:\n",
    "        urls.append(i.get_attribute('href'))\n",
    "    #loop to scrap required review from every page\n",
    "    for url in urls:\n",
    "        driver.get(url)\n",
    "        rating_tags=driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "        for j in rating_tags:\n",
    "            Rating.append(j.text)\n",
    "        summary=driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "        for i in summary:\n",
    "            Review_summary.append(i.text)\n",
    "        for k in driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\"):\n",
    "            Full_review.append(k.text)\n",
    "           \n",
    "        \n",
    "    iphone_df=pd.DataFrame({'Rating':Rating[:99],\n",
    "                        'Review_summary':Review_summary[:99],\n",
    "                        'Full_review':Full_review[:99]})\n",
    "    print(iphone_df)\n",
    "    iphone_df.to_csv('iphone11_review.csv', index = False)\n",
    "    \n",
    "    \n",
    "# Calling Function\n",
    "iphone11('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGR3QP11A&marketplace=FLIPKART')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and\n",
    "search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Brand                                Product_description  \\\n",
      "0     French Connection                            Sneakers For Men  (Grey)   \n",
      "1             Marc Ecko                            Sneakers For Men  (Grey)   \n",
      "2                Chevit   Combo Pack of 4 Casual Sneakers With Sneakers ...   \n",
      "3          Robbie jones   Casual Sneakers Shoes For Men Sneakers For Men...   \n",
      "4   World Wear Footwear   Combo Pack of 4 Latest Collection Stylish Casu...   \n",
      "..                   ...                                                ...   \n",
      "95            Rockfield                      Sneakers For Men  (Multicolor)   \n",
      "96               Kzaara                           Sneakers For Men  (Brown)   \n",
      "97                  MOU   Zar Check Sneakers Sneakers For Men  (Multicolor)   \n",
      "98             Fabbmate     Combo of Men's Casual Shoes.(Pack of 3) Snea...   \n",
      "99    French Connection                     Sneakers For Men  (Navy, White)   \n",
      "\n",
      "     price discount_percentage  \\\n",
      "0   ₹2,058             48% off   \n",
      "1   ₹1,049             52% off   \n",
      "2     ₹499             75% off   \n",
      "3     ₹399             60% off   \n",
      "4     ₹499             75% off   \n",
      "..     ...                 ...   \n",
      "95    ₹399             60% off   \n",
      "96    ₹284             43% off   \n",
      "97    ₹523             47% off   \n",
      "98  ₹1,099             63% off   \n",
      "99    ₹849             57% off   \n",
      "\n",
      "                                                 Link  \n",
      "0   https://www.flipkart.com/french-connection-sne...  \n",
      "1   https://www.flipkart.com/marc-ecko-sneakers-me...  \n",
      "2   https://www.flipkart.com/chevit-combo-pack-4-c...  \n",
      "3   https://www.flipkart.com/robbie-jones-casual-s...  \n",
      "4   https://www.flipkart.com/world-wear-footwear-c...  \n",
      "..                                                ...  \n",
      "95  https://www.flipkart.com/rockfield-sneakers-me...  \n",
      "96  https://www.flipkart.com/kzaara-sneakers-men/p...  \n",
      "97  https://www.flipkart.com/mou-zar-check-sneaker...  \n",
      "98  https://www.flipkart.com/fabbmate-combo-men-s-...  \n",
      "99  https://www.flipkart.com/french-connection-sne...  \n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Function Definition\n",
    "def flipkart_sneakers(url):\n",
    "    driver=webdriver.Chrome(r\"C:\\Users\\khurr\\Downloads\\chromedriver.exe\")\n",
    "    urls = []\n",
    "    brand=[]\n",
    "    product_desc=[]\n",
    "    price=[]\n",
    "    discount_per=[]\n",
    "    #looping to fetch urls of each sunglasses till page 5\n",
    "    driver.get(url)\n",
    "    page=[]\n",
    "    url=driver.find_elements_by_xpath(\"//nav[@class='yFHi8N']/a\")\n",
    "    for i in url[0:5]:\n",
    "        page.append(i.get_attribute('href'))\n",
    "    for i in page:\n",
    "        driver.get(i)\n",
    "        soup= BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        prod_urls = soup.find_all('a', attrs ={'class':'IRpwTa'})\n",
    "        for prod in prod_urls:\n",
    "            urls.append('https://www.flipkart.com'+prod.get('href'))\n",
    "            \n",
    "    #loop to scrap required details from each sunglasses page\n",
    "    for url in urls:\n",
    "        driver.get(url)\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        n = soup.find('span',attrs={'class':'G6XhRU'})\n",
    "        if n is not None:\n",
    "            brand.append(n.text.replace('\\n',''))\n",
    "        else:\n",
    "            brand.append('-')\n",
    "        desc = soup.find('span', attrs = {'class':'B_NuCI'})\n",
    "        if desc is not None:\n",
    "            product_desc.append(desc.text)\n",
    "        else:\n",
    "            product_desc.append('-')\n",
    "        prc = soup.find('div', attrs = {'class':'_30jeq3 _16Jk6d'})\n",
    "        if prc is not None:\n",
    "            price.append(prc.text.replace('\\n',''))\n",
    "        else:\n",
    "            price.append('-')\n",
    "        disc = soup.find('div', attrs = {'class':'_3Ay6Sb _31Dcoz pZkvcx'})\n",
    "        if disc is not None:\n",
    "            discount_per.append(disc.find('span').text.replace('\\n',''))\n",
    "        else:\n",
    "            discount_per.append('-')\n",
    "           \n",
    "        \n",
    "    sneakers_df=pd.DataFrame({'Brand':brand[:100],\n",
    "                           'Product_description':product_desc[:100],\n",
    "                            'price':price[:100],\n",
    "                            'discount_percentage':discount_per[:100],\n",
    "                            'Link':urls[:100]})\n",
    "    print(sneakers_df)\n",
    "    sneakers_df.to_csv('Flipkart_glass.csv', index = False)\n",
    "    \n",
    "    \n",
    "# Calling Function\n",
    "flipkart_sneakers('https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q9: Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”,And then scrape First 100 shoes data you get. The data should include “Brand” of\n",
    "the shoes , Short Shoe description, price of the shoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome(r\"C:\\Users\\khurr\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.myntra.com/shoes'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering price\n",
    "price=driver.find_element_by_xpath(\"//div[@class='vertical-filters-filters']//li[2]//label[@class='common-customCheckbox vertical-filters-label']//div[@class='common-checkboxIndicator']\")\n",
    "try:\n",
    "    price.click()\n",
    "except ElementNotInteractableException:\n",
    "    price.get_attribute('href')\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering color\n",
    "color=driver.find_element_by_xpath(\"//div[@class='vertical-filters-filters']//li[1][@class='colour-listItem']//div[@class='common-checkboxIndicator']\")\n",
    "try:\n",
    "    color.click()\n",
    "except ElementNotInteractableException:\n",
    "    color.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the list are ==>> 150 150 150 150\n",
      "             Brand                      Product_description     price  \\\n",
      "0             Nike                   Men Zoom Running Shoes  Rs. 6399   \n",
      "1             Nike                Men JORDAN ZOOM '92 Shoes  Rs. 9699   \n",
      "2             Nike                Men JORDAN ZOOM '92 Shoes  Rs. 9699   \n",
      "3     Kenneth Cole  Men Solid Formal Genuine Leather Derbys  Rs. 6153   \n",
      "4             Nike              Men JORDAN DELTA Basketball  Rs. 8999   \n",
      "..             ...                                      ...       ...   \n",
      "95  Tommy Hilfiger            Men Heritage Leather Sneakers  Rs. 7199   \n",
      "96    UNDER ARMOUR               Women Charged Breathe TR 2  Rs. 7999   \n",
      "97            Puma              SPEED Orbiter Running Shoes  Rs. 9699   \n",
      "98  Tommy Hilfiger             CHUNKY TECH Leather Sneakers  Rs. 7199   \n",
      "99    UNDER ARMOUR               Women HOVR Rise 2 Training  Rs. 9999   \n",
      "\n",
      "                                                 Link  \n",
      "0   https://www.myntra.com/sports-shoes/nike/nike-...  \n",
      "1   https://www.myntra.com/sports-shoes/nike/nike-...  \n",
      "2   https://www.myntra.com/sports-shoes/nike/nike-...  \n",
      "3   https://www.myntra.com/formal-shoes/kenneth-co...  \n",
      "4   https://www.myntra.com/sports-shoes/nike/nike-...  \n",
      "..                                                ...  \n",
      "95  https://www.myntra.com/casual-shoes/tommy-hilf...  \n",
      "96  https://www.myntra.com/sports-shoes/under-armo...  \n",
      "97  https://www.myntra.com/sports-shoes/puma/puma-...  \n",
      "98  https://www.myntra.com/casual-shoes/tommy-hilf...  \n",
      "99  https://www.myntra.com/sports-shoes/under-armo...  \n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#empty list to store the data\n",
    "Product_link=[]\n",
    "brand=[]\n",
    "product_desc=[]\n",
    "price=[]\n",
    "for i in range(0,3):\n",
    "    url_tags=driver.find_elements_by_xpath(\"//a[@target='_blank']\")\n",
    "    for j in url_tags:\n",
    "        Product_link.append(j.get_attribute('href'))\n",
    "    name_tags=driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")\n",
    "    for i in name_tags:\n",
    "        brand.append(i.text)\n",
    "    for k in driver.find_elements_by_xpath(\"//h4[@class='product-product']\"):\n",
    "        product_desc.append(k.text)\n",
    "    driver.find_element_by_xpath(\"//li[@class='pagination-next']/a\").click()\n",
    "    time.sleep(3)\n",
    "for i in Product_link:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        price.append((driver.find_element_by_xpath(\"//span[@class='pdp-price']\")).text)\n",
    "    except NoSuchElementException:\n",
    "        price.append(\"NA\")\n",
    "# as I extracted all the data\n",
    "# Before saving the data into a data frame length check the lenth all the data must be of equal lenghts before saving the data.\n",
    "print('Length of the list are ==>>',len(brand),len(product_desc),len(price),len(Product_link))\n",
    "# lets save the file in the data frame\n",
    "shoes_df=pd.DataFrame({'Brand':brand[:100],\n",
    "                    'Product_description':product_desc[:100],\n",
    "                    'price':price[:100],\n",
    "                    'Link':Product_link[:100]})\n",
    "print(shoes_df)\n",
    "shoes_df.to_csv('shoes_df_myntra.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q10: Go to webpage https://www.amazon.in/\n",
    " Enter “Laptop” in the search field and then click the search icon.\n",
    " Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” \n",
    " After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes\n",
    "for each laptop:\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the list are ==>> 140 140 140 140\n",
      "                                                Title       Ratings  \\\n",
      "0   Dell Inspiron 5501 15.6 Inch FHD Laptop (10th ...  3.4 out of 5   \n",
      "1   Dell Inspiron 5409 14.0\" FHD WVA AG Display 11...    4 out of 5   \n",
      "2   Mi Notebook Horizon Edition 14 Intel Core i5-1...  4.2 out of 5   \n",
      "3   (Renewed) Dell Latitude E7470 14-inch Laptop (...            NA   \n",
      "4   (Renewed) Dell Latitude E7470 14-inch Laptop (...            NA   \n",
      "..                                                ...           ...   \n",
      "95  ASUS VivoBook S S14 Intel Core i7-1165G7 11th ...  3.9 out of 5   \n",
      "96  (Renewed) HP Hybrid Probook Laptop 430G3 Intel...            NA   \n",
      "97  (Renewed) HP Hybrid Probook Laptop 430G3 Intel...            NA   \n",
      "98  (Renewed) HP Hybrid Probook Laptop 430G3 Intel...            NA   \n",
      "99  (Renewed) Dell Latitude E7470 14 inch Laptop C...            NA   \n",
      "\n",
      "          price                                        Link To Buy  \n",
      "0   ₹ 85,890.00  https://www.amazon.in/gp/slredirect/picassoRed...  \n",
      "1   ₹ 86,990.00  https://www.amazon.in/gp/slredirect/picassoRed...  \n",
      "2   ₹ 54,862.00  https://www.amazon.in/Notebook-Horizon-i5-1021...  \n",
      "3   ₹ 53,599.00  https://www.amazon.in/Renewed-Dell-Latitude-14...  \n",
      "4   ₹ 55,299.00  https://www.amazon.in/Renewed-Dell-Latitude-14...  \n",
      "..          ...                                                ...  \n",
      "95  ₹ 98,990.00  https://www.amazon.in/ASUS-VivoBook-i7-1165G7-...  \n",
      "96  ₹ 51,990.00  https://www.amazon.in/Renewed-HP-Hybrid-Proboo...  \n",
      "97  ₹ 48,490.00  https://www.amazon.in/Renewed-HP-Hybrid-Proboo...  \n",
      "98  ₹ 69,990.00  https://www.amazon.in/Renewed-HP-Hybrid-Proboo...  \n",
      "99  ₹ 53,699.00  https://www.amazon.in/Renewed-Dell-Latitude-In...  \n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Function Definition\n",
    "def amzon_laptop(url):\n",
    "    driver=webdriver.Chrome(r\"C:\\Users\\khurr\\Downloads\\chromedriver.exe\")\n",
    "    Product_link=[]\n",
    "    Title=[]\n",
    "    Ratings=[]\n",
    "    price=[]\n",
    "    driver.get(url)\n",
    "    #inspecting intel7\n",
    "    intel7=driver.find_element_by_xpath(\"//ul[@class='a-unordered-list a-nostyle a-vertical a-spacing-medium']//li[@id='p_n_feature_thirteen_browse-bin/12598163031']/span/a/div\")\n",
    "    try:\n",
    "        intel7.click()\n",
    "    except ElementNotInteractableException:\n",
    "        intel7.get_attribute('href')\n",
    "    #inspecting intel9\n",
    "    intel9=driver.find_element_by_xpath(\"//ul[@class='a-unordered-list a-nostyle a-vertical a-spacing-medium']//li[@id='p_n_feature_thirteen_browse-bin/16757432031']/span/a/div\")\n",
    "    try:\n",
    "        intel9.click()\n",
    "    except ElementNotInteractableException:\n",
    "        intel9.get_attribute('href')\n",
    "    #extracting Data of laptops.\n",
    "    for i in range(0,6):\n",
    "        url_tags=driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\")\n",
    "        for j in url_tags:\n",
    "            Product_link.append(j.get_attribute('href'))\n",
    "        name_tags=driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "        for i in name_tags:\n",
    "            Title.append(i.text)\n",
    "        time.sleep(3)\n",
    "        driver.find_element_by_xpath(\"//li[@class='a-last']\").click()\n",
    "        time.sleep(3)\n",
    "    for j in Product_link:\n",
    "        driver.get(j)\n",
    "        try:\n",
    "            price.append((driver.find_element_by_xpath(\"//td[@class='a-span12']/span\")).text)\n",
    "        except NoSuchElementException:\n",
    "            price.append(\"NA\")\n",
    "        try:\n",
    "            Ratings.append((driver.find_element_by_xpath(\"//span[@class='a-size-base a-nowrap']/span\")).text)\n",
    "        except NoSuchElementException:\n",
    "            Ratings.append(\"NA\")\n",
    "    # as I extracted all the data\n",
    "    # Before saving the data into a data frame length check the lenth all the data must be of equal lenghts before saving the data.\n",
    "    print('Length of the list are ==>>',len(Title),len(Ratings),len(price),len(Product_link))\n",
    "    #lets save the data in dataframe for further use\n",
    "    amazon_laptop=pd.DataFrame({'Title':Title[:100],\n",
    "                           'Ratings':Ratings[:100],\n",
    "                            'price':price[:100],\n",
    "                            'Link To Buy':Product_link[:100]})\n",
    "    print(amazon_laptop)\n",
    "    amazon_laptop.to_csv('amazon_laptop.csv', index = False)\n",
    "    \n",
    "    \n",
    "# Calling Function\n",
    "amzon_laptop('https://www.amazon.in/s?k=laptop&ref=nb_sb_noss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
